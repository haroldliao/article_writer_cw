from openai import OpenAI
import os
import re
from selector import load_style  # ğŸ”§ æ–°å¢ï¼šè¼‰å…¥ style_xxx.md

def load_prompt(path: str) -> str:
    """è¼‰å…¥ prompt æª”æ¡ˆ,åŒ…å«éŒ¯èª¤è™•ç†"""
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° prompt æª”æ¡ˆ: {path}")
    except Exception as e:
        raise Exception(f"è®€å–æª”æ¡ˆ {path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")


def basic_check(article: str) -> dict:
    """åŸºç¤æª¢æŸ¥æ–‡ç« å“è³ª"""
    word_count = len(article)
    paragraphs = article.count("\n\n") + 1
    quotes = len(re.findall(r"[ã€Œ\"]", article))
    
    return {
        "word_count": word_count,
        "paragraphs": paragraphs,
        "quotes": quotes,
        "within_range": 1500 <= word_count <= 2000,
        "has_enough_quotes": quotes >= 5
    }


def generate_article(
    subject: str,
    company: str,
    people: str,
    participants: str,
    transcript: str,
    summary_points: str,
    style_label: str = "ä¼æ¥­",  # ğŸ”§ æ–°å¢ï¼šä½¿ç”¨è€…é¸çš„é¢¨æ ¼é¡å‹
    word_count_range: tuple | None = None,
    paragraphs: int | None = None,
    api_key: str | None = None
) -> tuple[str, dict, int]:
    """
    æ ¹æ“šè¨ªè«‡è³‡æ–™ç”Ÿæˆæ–‡ç« ,è‹¥æª¢æŸ¥ä¸é€šéæœƒè‡ªå‹•ä¿®ç¨¿
    
    Returns:
        (æ–‡ç« å…§å®¹, æª¢æŸ¥çµæœ dict, ä¿®ç¨¿æ¬¡æ•¸)
    """
    client = OpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))
    
    # è¼‰å…¥ prompts
    system_prompt = load_prompt("cw_prompts/system_style.txt")
    template_prompt = load_prompt("cw_prompts/article_template.txt")
    style_prompt = load_style(style_label)  # ğŸ”§ æ–°å¢ï¼šè®€å– style_xxx.md
    
    def call_model(user_prompt: str, system_prompt: str, temperature=0.7, max_tokens=3500) -> str:
        """å‘¼å« OpenAI API ç”Ÿæˆå…§å®¹"""
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=temperature,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content.strip()
    
    # ç¬¬ä¸€æ¬¡ç”Ÿæˆ
    constraints_lines = []
    if word_count_range and len(word_count_range) == 2:
        constraints_lines.append(
            f"å…¨æ–‡å­—æ•¸å¿…é ˆåœ¨ {word_count_range[0]}â€“{word_count_range[1]} å­—ä¹‹é–“,ä½æ–¼ç¯„åœä¸å¯æ¥å—ã€‚"
        )
    if paragraphs:
        constraints_lines.append(
            f"ä¸»é«”æ®µè½å¿…é ˆå›ºå®šç‚º {paragraphs} æ®µ,æ¯æ®µç´„ 300â€“400 å­—,å…¶ä»–æ®µè½ä¸å¯é¡å¤–æ–°å¢ã€‚"
        )
    constraints_lines.append("å…¨æ–‡è‡³å°‘åŒ…å« 5 å‰‡ä»¥ä¸Šçš„å—è¨ªè€…ç›´æ¥å¼•è¨€(ä½¿ç”¨ã€Œã€æ¨™ç¤º)ã€‚")
    constraints_lines.append("æ¯ä¸€å€‹æ®µè½éƒ½å¿…é ˆæœ‰æ¸…æ¥šçš„å°æ¨™é¡Œ,ä½¿ç”¨ã€### å°æ¨™é¡Œã€æ ¼å¼æ¨™ç¤ºã€‚")
    
    constraints_text = "\n".join(constraints_lines)
    
    user_prompt = f"""
è«‹ä¾ç…§ä»¥ä¸‹æ–‡ç« æ¨¡æ¿,ç”Ÿæˆä¸€ç¯‡å®Œæ•´å°ˆè¨ªæ–‡ç« ã€‚

=== æ–‡ç« æ¨¡æ¿ ===
{template_prompt}

=== æ–‡ç« é¢¨æ ¼è¦æ±‚ ===
{style_prompt}

=== ç”¢å‡ºé™åˆ¶ ===
{constraints_text}

=== ä½¿ç”¨è€…è³‡æ–™ ===
ä¸»é¡Œ: {subject}
ä¼æ¥­åç¨±: {company}
äººç‰©å§“å: {people}
å—è¨ªè€…æ¸…å–®: {participants}

é€å­—ç¨¿(å·²æ¸…ç†):
{transcript}

é‡é»æ‘˜è¦:
{summary_points}
"""
    
    article = call_model(user_prompt, system_prompt)
    checks = basic_check(article)
    
    # è‡ªå‹•ä¿®ç¨¿æµç¨‹
    max_retries = 2
    retry_count = 0
    
    while (not checks["within_range"] or not checks["has_enough_quotes"]) and retry_count < max_retries:
        fix_prompt = f"""
ä»¥ä¸‹æ˜¯åˆç¨¿æ–‡ç« ,è«‹æ ¹æ“šä»¥ä¸‹è¦æ±‚é€²è¡Œä¿®æ­£:

- å­—æ•¸å¿…é ˆé”åˆ° {word_count_range[0]}â€“{word_count_range[1]} å­—
- ä¸»é«”æ®µè½å›ºå®šç‚º {paragraphs} æ®µ,æ¯æ®µ 300â€“400 å­—
- è‡³å°‘åŠ å…¥ 5 å‰‡å—è¨ªè€…ç›´æ¥å¼•è¨€(ã€Œã€)
- æ¯ä¸€å€‹æ®µè½éƒ½å¿…é ˆæœ‰æ¸…æ¥šçš„å°æ¨™é¡Œ,ä½¿ç”¨ã€### å°æ¨™é¡Œã€æ ¼å¼æ¨™ç¤º
- ä¿ç•™åŸæœ¬çš„é¢¨æ ¼èˆ‡å…§å®¹,åƒ…èª¿æ•´çµæ§‹èˆ‡ç¯‡å¹…

åˆç¨¿:
{article}
"""
        article = call_model(fix_prompt, "ä½ æ˜¯å°ˆæ¥­ç·¨è¼¯,è² è²¬èª¿æ•´æ–‡ç« çµæ§‹èˆ‡ç¯‡å¹…ã€‚", temperature=0.5)
        checks = basic_check(article)
        retry_count += 1
    
    return article, checks, retry_count


# æ¸¬è©¦ç”¨
if __name__ == "__main__":
    try:
        article, checks, retries = generate_article(
            subject="æ•¸ä½è½‰å‹æˆåŠŸæ¡ˆä¾‹",
            company="æŸæŸç§‘æŠ€å…¬å¸",
            people="å¼µåŸ·è¡Œé•·",
            participants="å¼µåŸ·è¡Œé•·ã€ææŠ€è¡“é•·",
            transcript="é€™æ˜¯è¨ªè«‡å…§å®¹...",
            summary_points="1. æˆåŠŸå°å…¥ AI\n2. æå‡æ•ˆç‡ 30%",
            style_label="ä¼æ¥­",  # ğŸ”§ æ¸¬è©¦æŒ‡å®šé¢¨æ ¼
            word_count_range=(1500, 2000),
            paragraphs=3
        )
        print(article[:500])
        print("\n=== æª¢æŸ¥çµæœ ===")
        print(checks)
        print(f"ä¿®ç¨¿æ¬¡æ•¸: {retries}")
    except Exception as e:
        print(f"éŒ¯èª¤: {e}")
