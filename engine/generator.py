import os
from openai import OpenAI

# === é˜²æ­¢ SDK proxy å•é¡Œ ===
def _clear_proxy_env():
    """å®‰å…¨æ¸…é™¤ä»£ç†ç’°å¢ƒè®Šæ•¸"""
    for var in ["HTTP_PROXY", "HTTPS_PROXY", "http_proxy", "https_proxy"]:
        if var in os.environ:
            print(f"âš ï¸ ç§»é™¤ç’°å¢ƒè®Šæ•¸ï¼š{var}")
            os.environ.pop(var, None)

# åœ¨ os è¼‰å…¥å®Œæˆå¾ŒåŸ·è¡Œæ¸…é™¤
_clear_proxy_env()

# === å°è£ OpenAI åˆå§‹åŒ–ï¼Œé˜²æ­¢ proxies åƒæ•¸å ±éŒ¯ ===
_original_init = OpenAI.__init__

def patched_init(self, *args, **kwargs):
    """è‡ªå‹•ç§»é™¤ä¸æ”¯æ´çš„ proxies åƒæ•¸"""
    if "proxies" in kwargs:
        print("âš ï¸ ç§»é™¤ä¸æ”¯æ´çš„ proxies åƒæ•¸")
        kwargs.pop("proxies")
    return _original_init(self, *args, **kwargs)

# å¥—ç”¨è£œä¸
OpenAI.__init__ = patched_init


# === ä¸»è¦ç¨‹å¼é–‹å§‹ ===
from typing import Dict, Tuple, List, TypedDict
from engine.template_loader import load_template

# === å¸¸æ•¸å®šç¾© ===
TRANSCRIPT_LENGTH_THRESHOLD = 8000
MAX_SEGMENT_LENGTH = 5000
DEFAULT_MODEL = "gpt-5-mini"
SUMMARY_MODEL = "gpt-4-turbo"
MAX_TOKENS_NORMAL = 4000
MAX_TOKENS_SAFE_MODE = 12000
TEMPERATURE = 0.7
TOP_P = 0.9
MAX_API_ATTEMPTS = 1


class ParticipantInfo(TypedDict):
    name: str
    title: str
    weight: str


def generate_article(
    subject: str,
    company: str,
    participants: str,
    transcript: str,
    summary_points: str,
    opening_style: str,
    opening_context: str,
    paragraphs: int,
    api_key: str,
    model: str = DEFAULT_MODEL,
    max_tokens: int = MAX_TOKENS_NORMAL
) -> Tuple[str, Dict, int]:
    """
    ç”Ÿæˆå°ˆè¨ªæ–‡ç« ï¼ˆæ”¯æ´é•·é€å­—ç¨¿å®‰å…¨æ¨¡å¼ + å¤šæ¨¡å‹é¸æ“‡ï¼‰
    """
    client = OpenAI(api_key=api_key)

    # === æ¨¡å‹åˆ¥åå°ç…§è¡¨ ===
    model_alias = {
        "gpt-5-mini": "gpt-5-mini",
        "gpt-4-turbo": "gpt-4-turbo",
        "gpt-5": "gpt-5",
        "gpt-4o-mini": "gpt-4o-mini",
        "gpt-4o": "gpt-4o",
    }
    
    selected_model = model_alias.get(model)
    if not selected_model:
        print(f"âš ï¸ æœªè­˜åˆ¥çš„æ¨¡å‹åç¨±ï¼š{model}ï¼Œè‡ªå‹•ä½¿ç”¨ {DEFAULT_MODEL}")
        selected_model = DEFAULT_MODEL

    # === è§£æå—è¨ªè€…è³‡è¨Š ===
    participants_info = _parse_participants(participants)
    participants_desc = _format_participants(participants_info)

    # === æª¢æŸ¥é€å­—ç¨¿é•·åº¦ ===
    transcript_length = _count_chars(transcript)
    safe_mode = transcript_length > TRANSCRIPT_LENGTH_THRESHOLD
    compressed_transcript = transcript

    if safe_mode:
        print(f"âš ï¸ å•Ÿç”¨é•·é€å­—ç¨¿å®‰å…¨æ¨¡å¼ï¼šé€å­—ç¨¿é•·åº¦ç´„ {transcript_length} å­—")
        compressed_transcript = summarize_long_transcript(
            client=client,
            transcript=transcript,
            model=SUMMARY_MODEL
        )

    # === è¼‰å…¥æ¨¡æ¿ ===
    try:
        template_text = load_template("article_template.txt")
    except Exception as e:
        error_msg = f"æ¨¡æ¿è¼‰å…¥å¤±æ•—ï¼š{str(e)}"
        print(f"âŒ {error_msg}")
        raise Exception(error_msg)

    # === System Prompt ===
    system_prompt = (
        "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ˆè¨ªå ±å°æ’°ç¨¿äººï¼Œæ“…é•·å°‡é€å­—ç¨¿è½‰åŒ–ç‚ºå…·æ•˜äº‹æ„Ÿèˆ‡é‚è¼¯çµæ§‹çš„å®Œæ•´æ–‡ç« ï¼Œ"
        "èƒ½ç²¾æº–æ§åˆ¶ç¯‡å¹…èˆ‡å¼•ç”¨æ¯”ä¾‹ï¼Œç¬¦åˆä¼æ¥­ï¼æ”¿åºœï¼æ•™è‚²ç­‰æ­£å¼å‡ºç‰ˆéœ€æ±‚ã€‚"
    )

    # === User Prompt ===
    user_prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šæ’°å¯«å®Œæ•´å°ˆè¨ªæ–‡ç« ï¼Œä¸¦çµåˆæ–‡ç« æ¨¡æ¿ä½œç‚ºåƒè€ƒï¼š

ã€æ–‡ç« è³‡è¨Šã€‘
ä¸»é¡Œï¼š{subject}
ä¼æ¥­ï¼š{company}
æ®µè½æ•¸ï¼š{paragraphs}
é–‹å ´é¢¨æ ¼ï¼š{opening_style}
æ¡è¨ªæƒ…å¢ƒï¼š{opening_context or 'ï¼ˆç„¡ç‰¹å®šæè¿°ï¼‰'}

ã€å—è¨ªè€…è³‡è¨Šã€‘
{participants_desc}

ã€é€å­—ç¨¿æ‘˜è¦å…§å®¹ã€‘
{compressed_transcript}

ã€é‡é»æ‘˜è¦ã€‘
{summary_points or 'ï¼ˆç„¡ç‰¹å®šæ‘˜è¦ï¼‰'}

ã€æ–‡ç« æ¨¡æ¿ã€‘
{template_text}

ã€æ’°å¯«è¦æ±‚ã€‘
1. çµæ§‹ï¼šé–‹å ´ + {paragraphs} æ®µä¸»é«” + çµèª
2. ä¸»è»¸äººç‰©å¼•ç”¨ç¯‡å¹…ç´„ 60â€“70%
3. æ–‡å­—èªæ°£ï¼šå°ˆæ¥­ã€çœŸå¯¦ã€æœ‰ç•«é¢æ„Ÿ
4. æ¯æ®µ 300â€“500 å­—ï¼Œå…¨ç¯‡ç´„ 1600â€“2000 å­—
5. è‹¥æª¢æ¸¬åˆ°ä¸­åœ‹æ…£ç”¨èªï¼Œè«‹è‡ªå‹•ä¿®æ­£ç‚ºå°ç£å¸¸ç”¨èªªæ³•
6. è«‹è¼¸å‡ºå®Œæ•´æ–‡ç« ï¼ˆå«ä¸»æ¨™é¡Œ # èˆ‡å°æ¨™é¡Œ ##ï¼‰ï¼Œæ®µè½ä¹‹é–“ä»¥ç©ºè¡Œåˆ†éš”
"""

    # === å‘¼å« APIï¼ˆä½¿ç”¨ Responses APIï¼‰ ===
    for attempt in range(MAX_API_ATTEMPTS):
        try:
            token_param = {}
            max_output = MAX_TOKENS_SAFE_MODE if safe_mode else max_tokens

            if "gpt-5" in selected_model:
                token_param = {"max_completion_tokens": min(max_output, 4000)}
            elif "gpt-4" in selected_model:
                token_param = {"max_completion_tokens": min(max_output, 8000)}
            else:
                token_param = {"max_completion_tokens": min(max_output, 4000)}

            print(f"ğŸ§  ä½¿ç”¨æ¨¡å‹ï¼š{selected_model}ï¼ŒToken åƒæ•¸ï¼š{token_param}")

            response = client.responses.create(
                model=selected_model,
                input=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                **token_param,
                temperature=TEMPERATURE,
                top_p=TOP_P
            )

            article = response.output_text.strip()
            checks = quality_check(article, paragraphs, participants_info)
            return article, checks, attempt

        except Exception as e:
            if attempt == MAX_API_ATTEMPTS - 1:
                raise Exception(f"API å‘¼å«å¤±æ•—ï¼ˆå·²é‡è©¦ {MAX_API_ATTEMPTS} æ¬¡ï¼‰ï¼š{e}")
            print(f"âš ï¸ API å‘¼å«å¤±æ•—ï¼Œæ­£åœ¨é‡è©¦ï¼ˆç¬¬ {attempt + 1} æ¬¡ï¼‰ï¼š{e}")

    raise Exception("æœªé æœŸéŒ¯èª¤ï¼šç”Ÿæˆå¤±æ•—")


def summarize_long_transcript(
    client: OpenAI, 
    transcript: str,
    model: str = SUMMARY_MODEL
) -> str:
    """ç•¶é€å­—ç¨¿è¶…éé–¾å€¼æ™‚ï¼Œè‡ªå‹•åŸ·è¡Œåˆ†æ®µæ‘˜è¦ã€‚"""
    segments = _split_transcript(transcript, MAX_SEGMENT_LENGTH)
    summaries = []
    
    for idx, seg in enumerate(segments, 1):
        print(f"ğŸ§© æ­£åœ¨æ‘˜è¦ç¬¬ {idx} æ®µï¼Œå…± {len(segments)} æ®µ...")
        try:
            response = client.responses.create(
                model=model,
                input=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ‘˜è¦å°ˆå®¶ï¼Œè«‹ä¿ç•™äººç‰©è§€é»ã€æ•¸æ“šã€äº‹ä»¶é‚è¼¯ã€‚"},
                    {"role": "user", "content": f"è«‹æ‘˜è¦ä»¥ä¸‹é€å­—ç¨¿å…§å®¹ï¼Œé™ 300â€“400 å­—ï¼š\n{seg}"}
                ],
                max_completion_tokens=800,
                temperature=0.5
            )
            summaries.append(response.output_text.strip())
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {idx} æ®µæ‘˜è¦å¤±æ•—ï¼š{e}")
            summaries.append(f"[æ‘˜è¦å¤±æ•—ï¼š{seg[:200]}...]")

    print("âœ… æ‘˜è¦å®Œæˆï¼Œçµ„åˆç‚ºå£“ç¸®ç‰ˆé€å­—ç¨¿")
    return "\n\n".join(summaries)


def _split_transcript(transcript: str, max_length: int) -> List[str]:
    """å°‡é€å­—ç¨¿åˆ†å‰²æˆå¤šå€‹æ®µè½"""
    lines = transcript.split("\n")
    segments, buffer = [], ""
    for line in lines:
        buffer += line + "\n"
        if len(buffer) > max_length:
            segments.append(buffer.strip())
            buffer = ""
    if buffer.strip():
        segments.append(buffer.strip())
    return segments


def _count_chars(text: str) -> int:
    """è¨ˆç®—æ–‡å­—å­—æ•¸ï¼ˆæ’é™¤ç©ºæ ¼å’Œæ›è¡Œï¼‰"""
    return len(text.replace(" ", "").replace("\n", ""))


def _parse_participants(participants: str) -> List[ParticipantInfo]:
    """è§£æå—è¨ªè€…è³‡è¨Š"""
    info = []
    for line in participants.split("\n"):
        line = line.strip()
        if not line:
            continue
        parts = [p.strip() for p in line.split("ï¼")]
        if len(parts) == 3:
            info.append({
                "name": parts[0],
                "title": parts[1],
                "weight": parts[2]
            })
    return info


def _format_participants(participants_info: List[ParticipantInfo]) -> str:
    """æ ¼å¼åŒ–å—è¨ªè€…è³‡è¨Šç‚ºæè¿°æ–‡å­—"""
    if not participants_info:
        return "ï¼ˆæœªæä¾›å—è¨ªè€…è³‡æ–™ï¼‰"
    return "\n".join([
        f"- {p['name']}ï¼ˆ{p['title']}ï¼‰- {'ä¸»è»¸äººç‰©' if p['weight'] == '1' else 'è¼”åŠ©äººç‰©'}"
        for p in participants_info
    ])


def quality_check(
    article: str, 
    expected_paragraphs: int, 
    participants: List[ParticipantInfo]
) -> Dict[str, bool]:
    """æª¢æŸ¥æ–‡ç« å“è³ª"""
    checks = {}
    checks["åŒ…å«ä¸»æ¨™é¡Œ"] = article.startswith("#")
    checks["åŒ…å«å¼•è¨€"] = "ã€Œ" in article and "ã€" in article
    paragraph_count = article.count("## ")
    checks["æ®µè½æ•¸ç¬¦åˆ"] = abs(paragraph_count - expected_paragraphs) <= 1
    word_count = _count_chars(article)
    checks["å­—æ•¸å……è¶³"] = 1500 <= word_count <= 2500
    main_names = [p["name"] for p in participants if p["weight"] == "1"]
    checks["æåŠä¸»è»¸äººç‰©"] = any(name in article for name in main_names) if main_names else True
    filler_words = ["éå¸¸æˆåŠŸ", "ååˆ†é‡è¦", "æ¥µç‚ºé—œéµ", "ç›¸ç•¶å„ªç§€", "ä»¤äººæ„Ÿå‹•", "å±•ç¾éå‡¡"]
    checks["é¿å…ç©ºæ³›è©å½™"] = not any(word in article for word in filler_words)
    return checks
