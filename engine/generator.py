# engine/generator.py
from openai import OpenAI
import os
import re
import json
from pathlib import Path

ROOT = Path(__file__).parent.parent
PROMPTS_DIR = ROOT / "cw_prompts"

# ==========================================================
# ğŸ”¹ é€šç”¨è¼‰å…¥å‡½å¼
# ==========================================================
def load_text(path: str | Path) -> str:
    """è¼‰å…¥ç´”æ–‡å­—æª”æ¡ˆ"""
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{p}")
    return p.read_text(encoding="utf-8")


def load_json(path: str | Path):
    """è¼‰å…¥ JSON æª”æ¡ˆ"""
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{p}")
    return json.loads(p.read_text(encoding="utf-8"))


# ==========================================================
# ğŸ”¹ æ–‡ç« å“è³ªåŸºç¤æª¢æŸ¥
# ==========================================================
def basic_check(article: str) -> dict:
    """ç°¡æ˜“æª¢æŸ¥ï¼šå­—æ•¸ã€æ®µè½ã€å¼•è™Ÿ"""
    chinese = len(re.findall(r"[\u4e00-\u9fff]", article))
    english = len(re.findall(r"\b[a-zA-Z]+\b", article))
    word_count = chinese + english
    paragraphs = len([b for b in article.split("\n\n") if b.strip()])
    quotes = len(re.findall(r"[ã€Œ\"]", article))

    return {
        "word_count": word_count,
        "paragraphs": paragraphs,
        "quotes": quotes,
        "within_range": 1500 <= word_count <= 2000,
        "has_enough_quotes": quotes >= 5
    }


# ==========================================================
# ğŸ”¹ é–‹å ´è¨­å®šçµ„è£ï¼ˆæ–°ç‰ˆ JSON è¦æ ¼ï¼‰
# ==========================================================
def _build_opening_block(style_label: str, context: dict | str):
    """
    å¾æ–°ç‰ˆ opening_styles.json å–å‡ºé¢¨æ ¼æ¨¡æ¿ï¼Œå¸¶å…¥æƒ…å¢ƒã€‚
    æ”¯æ´éŒ¯èª¤æª¢æŸ¥èˆ‡è‡ªå‹•å¼•å…¥ç¦æ­¢äº‹é … / å“è³ªæ¸…å–®ã€‚
    """
    data = load_json(PROMPTS_DIR / "opening_styles.json")

    styles = data.get("styles", {})
    general_rules = data.get("general_rules", {})
    schema = data.get("contextSchema", {})

    # è‹¥é¢¨æ ¼ä¸å­˜åœ¨ï¼Œä½¿ç”¨é è¨­å€¼
    if style_label not in styles:
        style_label = "å ´æ™¯å¼"

    # ğŸ”¸ è‹¥ context æ˜¯å­—ä¸²ï¼Œå˜—è©¦è½‰ç‚º dict
    if isinstance(context, str):
        try:
            context = json.loads(context)
        except Exception:
            context = {"setting": context.strip()}

    # ğŸ”¸ æª¢æŸ¥å¿…è¦æ¬„ä½
    required = schema.get("required", {}).keys()
    missing = [k for k in required if not context.get(k)]
    if missing:
        raise ValueError(f"ç¼ºå°‘å¿…è¦æ¡è¨ªæƒ…å¢ƒè³‡æ–™ï¼ˆ{', '.join(missing)}ï¼‰ï¼Œç„¡æ³•ç”Ÿæˆé–‹å ´ã€‚")

    style = styles[style_label]

    # ğŸ”¸ æ•´ç†ç¦æ­¢äº‹é …èˆ‡å“è³ªæª¢æŸ¥
    forbid_list = general_rules.get("ç¦æ­¢äº‹é …", [])
    quality_list = general_rules.get("å“è³ªæª¢æŸ¥æ¸…å–®", [])

    forbid = "\n".join([f"- {r}" for r in forbid_list])
    quality = "\n".join(quality_list)

    # ğŸ”¸ æ•´ç†å¯«ä½œæŒ‡å¼•
    writing_tips = ""
    if "å¯«ä½œæŒ‡å¼•" in style:
        writing_tips = "\n".join([f"- {k}ï¼š{v}" for k, v in style["å¯«ä½œæŒ‡å¼•"].items()])

    # ğŸ”¸ JSON æ ¼å¼åŒ–çš„æƒ…å¢ƒé¡¯ç¤º
    context_desc = json.dumps(context, ensure_ascii=False, indent=2)

    # ğŸ”¸ çµ„åˆé–‹å ´èªªæ˜å€å¡Š
    return f"""é–‹å ´é¢¨æ ¼ï¼š{style_label}

æ¡è¨ªæƒ…å¢ƒï¼ˆä¾æ“š contextSchema æä¾›ï¼‰ï¼š
{context_desc}

å¯«ä½œæŒ‡ä»¤ï¼š
{style.get('instructions', 'ï¼ˆç„¡ç‰¹å®šæŒ‡ä»¤ï¼‰')}

å¯«ä½œæŒ‡å¼•ï¼š
{writing_tips or 'ï¼ˆç„¡ç‰¹åˆ¥æŒ‡å¼•ï¼‰'}

ç¦æ­¢äº‹é …ï¼š
{forbid}

å“è³ªæª¢æŸ¥æ¸…å–®ï¼š
{quality}
"""


# ==========================================================
# ğŸ”¹ ä¸»å‡½å¼ï¼šæ–‡ç« ç”Ÿæˆ
# ==========================================================
def generate_article(
    subject: str,
    company: str,
    people: str,
    participants: str,
    transcript: str,
    summary_points: str,
    opening_style: str = "å ´æ™¯å¼",
    opening_context: dict | str = "",
    word_count_range: tuple | None = None,
    paragraphs: int | None = None,
    api_key: str | None = None
) -> tuple[str, dict, int]:
    """
    ç”Ÿæˆå°ˆè¨ªæ–‡ç« ã€‚
    å›å‚³ï¼š(æ–‡ç« å…§å®¹, æª¢æŸ¥çµæœ dict, ä¿®ç¨¿æ¬¡æ•¸)
    """
    client = OpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))

    # è¼‰å…¥ prompts
    system_prompt = load_text(PROMPTS_DIR / "system_style.txt")
    template_prompt = load_text(PROMPTS_DIR / "article_template.txt")

    # === ç”¢å‡ºé™åˆ¶ ===
    constraints_lines = []
    if word_count_range and len(word_count_range) == 2:
        constraints_lines.append(
            f"å…¨æ–‡å­—æ•¸å¿…é ˆåœ¨ {word_count_range[0]}â€“{word_count_range[1]} å­—ä¹‹é–“ã€‚"
        )
    if paragraphs:
        constraints_lines.append(
            f"ä¸»é«”æ®µè½å›ºå®šç‚º {paragraphs} æ®µï¼Œæ¯æ®µç´„ 300â€“400 å­—ã€‚"
        )

    constraints_lines.extend([
        "å…¨æ–‡è‡³å°‘åŒ…å« 5 å‰‡ä»¥ä¸Šçš„å—è¨ªè€…ç›´æ¥å¼•è¨€ï¼ˆä½¿ç”¨ã€Œã€æ¨™ç¤ºï¼‰ã€‚",
        "æ¯ä¸€å€‹æ®µè½éƒ½å¿…é ˆæœ‰æ¸…æ¥šçš„å°æ¨™é¡Œï¼Œä½¿ç”¨ã€### å°æ¨™é¡Œã€æ ¼å¼æ¨™ç¤ºã€‚",
        "é–‹å ´æ®µè½ 150â€“200 å­—ï¼Œéœ€è‡ªç„¶éŠœæ¥ä¸»é¡Œï¼Œå…è¨± Â±20 å­—ã€‚"
    ])
    constraints_text = "\n".join(constraints_lines)

    # === é–‹å ´è¨­å®šå€å¡Šï¼ˆæ–°ç‰ˆï¼‰===
    opening_block = _build_opening_block(opening_style, opening_context)

    # === ä½¿ç”¨è€…è¼¸å…¥çµ„è£ ===
    user_prompt = f"""è«‹ä¾ç…§ä»¥ä¸‹æ–‡ç« æ¨¡æ¿ç”Ÿæˆä¸€ç¯‡å®Œæ•´å°ˆè¨ªæ–‡ç« ã€‚

=== æ–‡ç« æ¨¡æ¿ ===
{template_prompt}

=== ç”¢å‡ºé™åˆ¶ ===
{constraints_text}

=== é–‹å ´è¨­å®šï¼ˆå¿…é ˆéµå¾ªï¼‰ ===
{opening_block}

=== ä½¿ç”¨è€…è³‡æ–™ ===
ä¸»é¡Œï¼š{subject}
ä¼æ¥­åç¨±ï¼š{company}
äººç‰©å§“åï¼š{people}
å—è¨ªè€…æ¸…å–®ï¼š{participants}

é€å­—ç¨¿ï¼ˆå·²æ¸…ç†ï¼‰ï¼š
{transcript}

é‡é»æ‘˜è¦ï¼š
{summary_points}
"""

    # ==========================================================
    # ğŸ”¹ å‘¼å«æ¨¡å‹
    # ==========================================================
    def call_model(prompt: str, sys: str, temperature=0.7, max_tokens=3500) -> str:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": sys},
                {"role": "user", "content": prompt},
            ],
            temperature=temperature,
            max_tokens=max_tokens
        )
        return resp.choices[0].message.content.strip()

    # === ç¬¬ä¸€æ¬¡ç”Ÿæˆ ===
    article = call_model(user_prompt, system_prompt)
    checks = basic_check(article)

    # ==========================================================
    # ğŸ”¹ è‡ªå‹•ä¿®ç¨¿å¾ªç’°
    # ==========================================================
    max_retries, retry_count = 2, 0
    while (not checks["within_range"] or not checks["has_enough_quotes"]) and retry_count < max_retries:
        fix_prompt = f"""ä»¥ä¸‹æ˜¯åˆç¨¿æ–‡ç« ï¼Œè«‹ä¾éœ€æ±‚ä¿®æ­£ï¼ˆä¿æŒèªæ°£èˆ‡å…§å®¹ï¼‰ï¼š

=== ä¿®æ­£è¦æ±‚ ===
{constraints_text}

=== é–‹å ´è¨­å®š ===
{opening_block}

=== åˆç¨¿ ===
{article}

è«‹æ ¹æ“šã€Œé–‹å ´è¨­å®šã€åŠã€Œé€šç”¨è¦å‰‡ã€ä¿®æ­£ç¯‡å¹…èˆ‡çµæ§‹ï¼Œ
é¿å…é‡è¤‡æˆ–æ‹–æ²“ï¼Œç¢ºä¿èªæ°£è‡ªç„¶æµæš¢ã€‚
"""
        article = call_model(
            fix_prompt,
            "ä½ æ˜¯å°ˆæ¥­ç·¨è¼¯ï¼Œè² è²¬èª¿æ•´æ–‡ç« çµæ§‹èˆ‡ç¯‡å¹…ã€‚",
            temperature=0.5
        )
        checks = basic_check(article)
        retry_count += 1

    return article, checks, retry_count


# ==========================================================
# ğŸ”¹ æ¸¬è©¦åŸ·è¡Œ
# ==========================================================
if __name__ == "__main__":
    try:
        context_example = {
            "interviewee": "å¼µç‘‹ï¼Œå»ºç¯‰å¸«",
            "topic": "èˆŠåŸå†ç”Ÿè¨ˆç•«",
            "transcript": "ã€Œé‚£è£¡ä»¥å‰æ˜¯æˆ‘çˆ¸çš„å°åˆ·å» ã€‚ã€",
            "setting": "å°ä¸­èˆŠå¸‚å€è€å·¥å» ",
            "datetime": "2025å¹´5æœˆåˆå¾Œ",
            "background": "ç¬¬äºŒä»£å‰µæ¥­è€…",
            "keyData": "åŸå¸‚æ›´æ–°ç¬¬ä¸‰æœŸï¼ŒæŠ•å…¥ç¶“è²»2.3å„„å…ƒ"
        }

        article, checks, retries = generate_article(
            subject="èˆŠåŸå†ç”Ÿèˆ‡é’å¹´å‰µæ¥­",
            company="ç¯‰åŸè¨­è¨ˆäº‹å‹™æ‰€",
            people="å¼µç‘‹",
            participants="å¼µç‘‹ã€è¨­è¨ˆåœ˜éšŠ",
            transcript="é€™æ˜¯è¨ªè«‡é€å­—ç¨¿å…§å®¹...",
            summary_points="1. èˆŠåŸç©ºé–“å†åˆ©ç”¨\n2. é’å¹´è¿”é„‰å‰µæ¥­\n3. ç¶ å»ºç¯‰ç†å¿µæ¨å»£",
            opening_style="å ´æ™¯å¼",
            opening_context=context_example,
            word_count_range=(1500, 2000),
            paragraphs=3
        )

        print(article[:500])
        print("\n=== æª¢æŸ¥çµæœ ===")
        print(checks)
        print(f"ä¿®ç¨¿æ¬¡æ•¸: {retries}")

    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}")
