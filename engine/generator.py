# ==========================================================
#  generator.pyï¼ˆç©©å®šç‰ˆ - åƒ…ä½¿ç”¨ gpt-4o-mini å’Œ gpt-4oï¼‰
# ==========================================================

import os

# æ¸…é™¤å¯èƒ½çš„ä»£ç†ç’°å¢ƒè®Šæ•¸
for _k in [
    "HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY",
    "http_proxy", "https_proxy", "all_proxy",
]:
    os.environ.pop(_k, None)

# é€šçŸ¥ SDK ä¸èµ°ä»»ä½•ä»£ç†
os.environ["NO_PROXY"] = "*"
os.environ["no_proxy"] = "*"

print("âœ… ç’°å¢ƒè®Šæ•¸æ¸…ç†å®Œæˆ")

# ==========================================================
# ä¸»è¦ç”Ÿæˆé‚è¼¯
# ==========================================================
from openai import OpenAI
from typing import Dict, Tuple, List, TypedDict
from engine.template_loader import load_template

# === å¸¸æ•¸å®šç¾© ===
TRANSCRIPT_LENGTH_THRESHOLD = 8000
MAX_SEGMENT_LENGTH = 5000
DEFAULT_MODEL = "gpt-4o-mini"
SUMMARY_MODEL = "gpt-4o"
MAX_TOKENS_NORMAL = 4000
MAX_TOKENS_SAFE_MODE = 8000
TEMPERATURE = 0.7
TOP_P = 0.9
MAX_API_ATTEMPTS = 2


class ParticipantInfo(TypedDict):
    name: str
    title: str
    weight: str


def generate_article(
    subject: str,
    company: str,
    participants: str,
    transcript: str,
    summary_points: str,
    opening_style: str,
    opening_context: str,
    paragraphs: int,
    api_key: str,
    model: str = DEFAULT_MODEL,
    max_tokens: int = MAX_TOKENS_NORMAL
) -> Tuple[str, Dict, int]:
    """ç”Ÿæˆå°ˆè¨ªæ–‡ç« ï¼ˆæ”¯æ´ gpt-4o-mini å’Œ gpt-4oï¼‰"""

    # === æ¨¡å‹åˆ¥åæ˜ å°„ ===
    model_alias = {
        "gpt-5-mini": "gpt-4o-mini",
        "gpt-4-turbo": "gpt-4o",
        "gpt-5": "gpt-4o",
        "å¿«é€Ÿæ¸¬è©¦": "gpt-4o-mini",
        "æ­£å¼ç”Ÿæˆ": "gpt-4o",
        "gpt-4o-mini": "gpt-4o-mini",
        "gpt-4o": "gpt-4o",
    }
    selected_model = model_alias.get(model, DEFAULT_MODEL)
    print(f"ğŸ§  æ¨¡å‹é¸æ“‡ï¼š{model} â†’ {selected_model}")

    # === è§£æå—è¨ªè€… ===
    participants_info = _parse_participants(participants)
    participants_desc = _format_participants(participants_info)

    # === é•·é€å­—ç¨¿æ¨¡å¼ ===
    transcript_length = _count_chars(transcript)
    safe_mode = transcript_length > TRANSCRIPT_LENGTH_THRESHOLD
    compressed_transcript = transcript

    if safe_mode:
        print(f"âš ï¸ å•Ÿç”¨é•·é€å­—ç¨¿å®‰å…¨æ¨¡å¼ï¼ˆç´„ {transcript_length} å­—ï¼‰")
        compressed_transcript = summarize_long_transcript(transcript, SUMMARY_MODEL, api_key)

    # === è¼‰å…¥æ¨¡æ¿ ===
    try:
        template_text = load_template("article_template.txt")
        template_length = len(template_text)
        print(f"âœ… æ¨¡æ¿è¼‰å…¥æˆåŠŸï¼ˆç´„ {template_length} å­—ï¼‰")
    except Exception as e:
        raise Exception(f"æ¨¡æ¿è¼‰å…¥å¤±æ•—ï¼š{str(e)}")

    # === å¼·åŒ–çš„ System Prompt ===
    system_prompt = """ä½ æ˜¯ä¸€ä½è³‡æ·±å°ˆè¨ªä½œè€…ï¼Œç†Ÿæ‚‰å•†æ¥­ã€æ•™è‚²ã€èˆ‡å…¬å…±è­°é¡Œå ±å°ã€‚

ã€æ ¸å¿ƒè¦æ±‚ã€‘
1. å¿…é ˆåš´æ ¼éµå¾ªã€Œæ–‡ç« æ¨¡æ¿ã€çš„æ‰€æœ‰æŒ‡ç¤ºèˆ‡çµæ§‹è¦ç¯„
2. å…¨æ–‡å­—æ•¸æ§åˆ¶åœ¨ 1500â€“2000 å­—
3. æ–‡ç« çµæ§‹ï¼šé–‹å ´ â†’ ä¸»é«”æ®µè½ â†’ çµèª
4. æ¯æ®µè‡³å°‘åŒ…å«ä¸€å‰‡ç›´æ¥å¼•è¨€ï¼Œä½¿ç”¨å…¨å½¢å¼•è™Ÿã€Œã€
5. æ‰€æœ‰å¼•è¨€èˆ‡è³‡è¨Šå‡é ˆä¾†è‡ªé€å­—ç¨¿ï¼Œä¸å¾—æé€ 
6. èªæ°£å°ˆæ¥­ã€è‡ªç„¶ã€å…·æº«åº¦èˆ‡è§€å¯Ÿæ€§
7. æ¯å€‹æ®µè½éœ€è¦åŠ ä¸Šç°¡æ½”ç²¾ç…‰çš„å°æ¨™é¡Œï¼ˆ## æ ¼å¼ï¼‰
8. æ®µè½ç¯€å¥éœ€ä¿æŒè¼•é‡æœ‰è‡´ï¼Œé¿å…å¹³é‹ªç›´æ•˜

ã€èªè¨€è¦æ±‚ã€‘
- ä½¿ç”¨å°ç£æ…£ç”¨èªï¼Œé¿å…ä¸­åœ‹å¤§é™¸ç”¨èª
- çµ±ä¸€ä½¿ç”¨ï¼šå…¬éƒ¨é–€ã€ä½¿ç”¨è€…ã€ç¶²è·¯ã€é«˜å“è³ªã€å¯¦éš›å°å…¥ã€æ•´åˆã€é ˜åŸŸã€ç®¡ç†ã€æå‡æ•ˆç‡
- é¿å…ä½¿ç”¨ï¼šäº’è¯ç¶²ã€é«˜è³ªé‡ã€è½åœ°ã€æ‰“é€šã€è³½é“ã€ç®¡æ§ã€ææ•ˆã€å¢é‡

ã€å¯«ä½œåŸå‰‡ã€‘
- ä»¥ç¬¬ä¸‰äººç¨±æ—ç™½æ’°å¯«
- ä¿æŒå°ˆæ¥­ä¸­æ€§ï¼Œä¸ä½¿ç”¨æ¨éŠ·èªæ°£
- ç”¨å…·é«”ç´°ç¯€å–ä»£æŠ½è±¡å½¢å®¹
- æ®µè½é–‹é ­å…·è½‰å ´èªï¼Œé¿å…é€£çºŒä»¥å¼•è¨€é–‹é ­

è«‹å®Œå…¨æŒ‰ç…§ã€Œæ–‡ç« æ¨¡æ¿ã€çš„è©³ç´°è¦ç¯„åŸ·è¡Œã€‚"""

    # === å„ªåŒ–çš„ User Prompt ===
    user_prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šæ’°å¯«å®Œæ•´å°ˆè¨ªæ–‡ç« ã€‚

ã€æ–‡ç« è³‡è¨Šã€‘
ä¸»é¡Œï¼š{subject}
ä¼æ¥­/çµ„ç¹”ï¼š{company}
æ®µè½æ•¸ï¼š{paragraphs}
é–‹å ´é¢¨æ ¼ï¼š{opening_style}
æ¡è¨ªæƒ…å¢ƒï¼š{opening_context or 'ï¼ˆç„¡ç‰¹å®šæè¿°ï¼‰'}

ã€å—è¨ªè€…è³‡è¨Šã€‘
{participants_desc}

ã€é€å­—ç¨¿å…§å®¹ã€‘
{compressed_transcript}

ã€é‡é»æ‘˜è¦ã€‘
{summary_points or 'ï¼ˆç„¡é‡é»æ‘˜è¦ï¼‰'}

========================================
ã€æ–‡ç« æ¨¡æ¿ - è«‹åš´æ ¼éµå¾ªã€‘
========================================
{template_text}
========================================

ã€æœ€çµ‚æª¢æŸ¥æ¸…å–®ã€‘
ç”Ÿæˆæ–‡ç« å¾Œï¼Œè«‹ç¢ºèªï¼š
âœ“ å­—æ•¸ 1500-2000 å­—
âœ“ æ¯æ®µç´„ 300-400 å­—
âœ“ åŒ…å« 4-6 å‰‡å¼•è¨€
âœ“ é–‹å ´å…·é«”ä¸”å¸å¼•äºº
âœ“ çµèªå‘¼æ‡‰é–‹å ´
âœ“ ä½¿ç”¨å°ç£æ…£ç”¨èª
âœ“ å°æ¨™é¡Œæ ¼å¼æ­£ç¢ºï¼ˆ##ï¼‰
âœ“ ä¸»æ¨™é¡Œæ ¼å¼æ­£ç¢ºï¼ˆ#ï¼‰

ç¾åœ¨è«‹é–‹å§‹æ’°å¯«å®Œæ•´æ–‡ç« ã€‚"""

    # === å‘¼å« Chat Completions API ===
    client = OpenAI(api_key=api_key)
    
    for attempt in range(MAX_API_ATTEMPTS):
        try:
            print(f"ğŸ”„ å˜—è©¦ç”Ÿæˆæ–‡ç« ï¼ˆç¬¬ {attempt + 1}/{MAX_API_ATTEMPTS} æ¬¡ï¼‰")
            
            response = client.chat.completions.create(
                model=selected_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=TEMPERATURE,
                top_p=TOP_P,
                max_tokens=min(max_tokens, 16000),
            )

            article = response.choices[0].message.content.strip()
            checks = quality_check(article, paragraphs, participants_info)
            
            print(f"âœ… æ–‡ç« ç”ŸæˆæˆåŠŸï¼ˆå­—æ•¸ï¼š{_count_chars(article)}ï¼‰")
            return article, checks, attempt

        except Exception as e:
            error_msg = str(e)
            print(f"âš ï¸ API å‘¼å«å¤±æ•—ï¼ˆç¬¬ {attempt + 1} æ¬¡ï¼‰ï¼š{error_msg}")
            
            if attempt == MAX_API_ATTEMPTS - 1:
                raise Exception(f"API å‘¼å«å¤±æ•—ï¼ˆå·²é‡è©¦ {MAX_API_ATTEMPTS} æ¬¡ï¼‰ï¼š{error_msg}")

    raise Exception("æœªé æœŸéŒ¯èª¤ï¼šç”Ÿæˆå¤±æ•—")


def summarize_long_transcript(transcript: str, model: str, api_key: str) -> str:
    """é•·é€å­—ç¨¿æ‘˜è¦æ¨¡å¼"""
    client = OpenAI(api_key=api_key)
    segments = _split_transcript(transcript, MAX_SEGMENT_LENGTH)
    summaries = []
    
    for idx, seg in enumerate(segments, 1):
        print(f"ğŸ§© æ­£åœ¨æ‘˜è¦ç¬¬ {idx} æ®µ / å…± {len(segments)} æ®µ")
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ‘˜è¦å°ˆå®¶ï¼Œè«‹ä¿ç•™äººç‰©è§€é»ã€æ•¸æ“šã€äº‹ä»¶é‚è¼¯ã€‚"},
                    {"role": "user", "content": f"è«‹æ‘˜è¦ä»¥ä¸‹é€å­—ç¨¿å…§å®¹ï¼Œé™ 300â€“400 å­—ï¼š\n{seg}"},
                ],
                temperature=0.5,
                max_tokens=800,
            )
            summaries.append(response.choices[0].message.content.strip())
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {idx} æ®µæ‘˜è¦å¤±æ•—ï¼š{e}")
            summaries.append(f"[æ‘˜è¦å¤±æ•—ï¼š{seg[:200]}...]")
    
    print("âœ… æ‘˜è¦å®Œæˆï¼Œçµ„åˆç‚ºå£“ç¸®ç‰ˆé€å­—ç¨¿")
    return "\n\n".join(summaries)


def _split_transcript(transcript: str, max_length: int) -> List[str]:
    """å°‡é€å­—ç¨¿åˆ†å‰²æˆå¤šå€‹æ®µè½"""
    lines = transcript.split("\n")
    segments, buffer = [], ""
    for line in lines:
        buffer += line + "\n"
        if len(buffer) > max_length:
            segments.append(buffer.strip())
            buffer = ""
    if buffer.strip():
        segments.append(buffer.strip())
    return segments


def _count_chars(text: str) -> int:
    """è¨ˆç®—æ–‡å­—å­—æ•¸ï¼ˆæ’é™¤ç©ºæ ¼å’Œæ›è¡Œï¼‰"""
    return len(text.replace(" ", "").replace("\n", ""))


def _parse_participants(participants: str) -> List[ParticipantInfo]:
    """è§£æå—è¨ªè€…è³‡è¨Š"""
    info = []
    for line in participants.split("\n"):
        line = line.strip()
        if not line:
            continue
        parts = [p.strip() for p in line.split("ï¼")]
        if len(parts) == 3:
            info.append({"name": parts[0], "title": parts[1], "weight": parts[2]})
    return info


def _format_participants(participants_info: List[ParticipantInfo]) -> str:
    """æ ¼å¼åŒ–å—è¨ªè€…è³‡è¨Šç‚ºæè¿°æ–‡å­—"""
    if not participants_info:
        return "ï¼ˆæœªæä¾›å—è¨ªè€…è³‡æ–™ï¼‰"
    return "\n".join([
        f"- {p['name']}ï¼ˆ{p['title']}ï¼‰- {'ä¸»è»¸äººç‰©' if p['weight'] == '1' else 'è¼”åŠ©äººç‰©'}"
        for p in participants_info
    ])


def quality_check(
    article: str,
    expected_paragraphs: int,
    participants: List[ParticipantInfo]
) -> Dict[str, bool]:
    """æª¢æŸ¥æ–‡ç« å“è³ª"""
    checks = {}
    checks["åŒ…å«ä¸»æ¨™é¡Œ"] = article.startswith("#")
    checks["åŒ…å«å¼•è¨€"] = "ã€Œ" in article and "ã€" in article
    paragraph_count = article.count("## ")
    checks["æ®µè½æ•¸ç¬¦åˆ"] = abs(paragraph_count - expected_paragraphs) <= 1
    word_count = _count_chars(article)
    checks["å­—æ•¸å……è¶³"] = 1500 <= word_count <= 2500
    main_names = [p["name"] for p in participants if p["weight"] == "1"]
    checks["æåŠä¸»è»¸äººç‰©"] = any(name in article for name in main_names) if main_names else True
    filler_words = ["éå¸¸æˆåŠŸ", "ååˆ†é‡è¦", "æ¥µç‚ºé—œéµ", "ç›¸ç•¶å„ªç§€", "ä»¤äººæ„Ÿå‹•", "å±•ç¾éå‡¡"]
    checks["é¿å…ç©ºæ³›è©å½™"] = not any(word in article for word in filler_words)
    return checks


