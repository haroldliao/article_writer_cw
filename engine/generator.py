# engine/generator.py
from openai import OpenAI
import os
import re
import json
from pathlib import Path

ROOT = Path(__file__).parent.parent
PROMPTS_DIR = ROOT / "cw_prompts"

# ==========================================================
# ğŸ”¹ é€šç”¨è¼‰å…¥å‡½å¼
# ==========================================================
def load_text(path: str | Path) -> str:
    """è¼‰å…¥ç´”æ–‡å­—æª”æ¡ˆ"""
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{p}")
    return p.read_text(encoding="utf-8")


def load_json(path: str | Path):
    """è¼‰å…¥ JSON æª”æ¡ˆ"""
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{p}")
    return json.loads(p.read_text(encoding="utf-8"))


# ==========================================================
# ğŸ”¹ æ–‡ç« å“è³ªåŸºç¤æª¢æŸ¥
# ==========================================================
def basic_check(article: str) -> dict:
    """ç°¡æ˜“æª¢æŸ¥ï¼šå­—æ•¸ã€æ®µè½ã€å¼•è™Ÿ"""
    chinese = len(re.findall(r"[\u4e00-\u9fff]", article))
    english = len(re.findall(r"\b[a-zA-Z]+\b", article))
    word_count = chinese + english
    paragraphs = len([b for b in article.split("\n\n") if b.strip()])
    quotes = len(re.findall(r"[ã€Œ\"]", article))

    return {
        "word_count": word_count,
        "paragraphs": paragraphs,
        "quotes": quotes,
        "within_range": 1500 <= word_count <= 2000,
        "has_enough_quotes": quotes >= 5
    }


# ==========================================================
# ğŸ”¹ é–‹å ´è¨­å®šçµ„è£ï¼ˆæ–°ç‰ˆ JSON è¦æ ¼ï¼‰
# ==========================================================
def _build_opening_block(style_label: str, context: dict | str):
    """
    å¾æ–°ç‰ˆ opening_styles.json å–å‡ºé¢¨æ ¼æ¨¡æ¿ï¼Œå¸¶å…¥æƒ…å¢ƒã€‚
    æ”¯æ´éŒ¯èª¤æª¢æŸ¥èˆ‡è‡ªå‹•å¼•å…¥ç¦æ­¢äº‹é … / å“è³ªæ¸…å–®ã€‚
    """
    data = load_json(PROMPTS_DIR / "opening_styles.json")

    styles = data.get("styles", {})
    general_rules = data.get("general_rules", {})
    schema = data.get("contextSchema", {})

    # è‹¥é¢¨æ ¼ä¸å­˜åœ¨ï¼Œä½¿ç”¨é è¨­å€¼
    if style_label not in styles:
        style_label = "å ´æ™¯å¼"

    # ğŸ”¸ è‹¥ context æ˜¯å­—ä¸²ï¼Œå˜—è©¦è½‰ç‚º dict
    if isinstance(context, str):
        try:
            context = json.loads(context)
        except Exception:
            context = {"setting": context.strip()}

    # ğŸ”¸ æª¢æŸ¥å¿…è¦æ¬„ä½
    required = schema.get("required", {}).keys()
    missing = [k for k in required if not context.get(k)]
    if missing:
        raise ValueError(f"ç¼ºå°‘å¿…è¦æ¡è¨ªæƒ…å¢ƒè³‡æ–™ï¼ˆ{', '.join(missing)}ï¼‰ï¼Œç„¡æ³•ç”Ÿæˆé–‹å ´ã€‚")

    style = styles[style_label]

    # ğŸ”¸ æ•´ç†ç¦æ­¢äº‹é …èˆ‡å“è³ªæª¢æŸ¥
    forbid_list = general_rules.get("ç¦æ­¢äº‹é …", [])
    quality_list = general_rules.get("å“è³ªæª¢æŸ¥æ¸…å–®", [])

    forbid = "\n".join([f"- {r}" for r in forbid_list])
    quality = "\n".join(quality_list)

    # ğŸ”¸ æ•´ç†å¯«ä½œæŒ‡å¼•
    writing_tips = ""
    if "å¯«ä½œæŒ‡å¼•" in style:
        writing_tips = "\n".join([f"- {k}ï¼š{v}" for k, v in style["å¯«ä½œæŒ‡å¼•"].items()])

    # ğŸ”¸ JSON æ ¼å¼åŒ–çš„æƒ…å¢ƒé¡¯ç¤º
    context_desc = json.dumps(context, ensure_ascii=False, indent=2)

    # ğŸ”¸ çµ„åˆé–‹å ´èªªæ˜å€å¡Š
    return f"""é–‹å ´é¢¨æ ¼ï¼š{style_label}

æ¡è¨ªæƒ…å¢ƒï¼ˆä¾æ“š contextSchema æä¾›ï¼‰ï¼š
{context_desc}

å¯«ä½œæŒ‡ä»¤ï¼š
{style.get('instructions', 'ï¼ˆç„¡ç‰¹å®šæŒ‡ä»¤ï¼‰')}

å¯«ä½œæŒ‡å¼•ï¼š
{writing_tips or 'ï¼ˆç„¡ç‰¹åˆ¥æŒ‡å¼•ï¼‰'}

ç¦æ­¢äº‹é …ï¼š
{forbid}

å“è³ªæª¢æŸ¥æ¸…å–®ï¼š
{quality}
"""


# ==========================================================
# ğŸ”¹ ä¸»å‡½å¼ï¼šæ–‡ç« ç”Ÿæˆ
# ==========================================================
def generate_article(
    subject: str,
    company: str,
    people: str,
    participants: str,
    transcript: str,
    summary_points: str,
    opening_style: str = "å ´æ™¯å¼",
    opening_context: dict | str = "",
    word_count_range: tuple | None = None,
    paragraphs: int | None = None,
    api_key: str | None = None
) -> tuple[str, dict, int]:
    """
    ç”Ÿæˆå°ˆè¨ªæ–‡ç« ã€‚
    å›å‚³ï¼š(æ–‡ç« å…§å®¹, æª¢æŸ¥çµæœ dict, ä¿®ç¨¿æ¬¡æ•¸)
    """
    client = OpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))

    # è¼‰å…¥ prompts
    system_prompt = load_text(PROMPTS_DIR / "system_style.txt")
    template_prompt = load_text(PROMPTS_DIR / "article_template.txt")

    # === ç”¢å‡ºé™åˆ¶ ===
    constraints_lines = []
    if word_count_range and len(word_count_range) == 2:
        constraints_lines.append(
            f"å…¨æ–‡å­—æ•¸å¿…é ˆåœ¨ {word_count_range[0]}â€“{word_count_range[1]} å­—ä¹‹é–“ã€‚"
        )
    if paragraphs:
        constraints_lines.append(
            f"ä¸»é«”æ®µè½å›ºå®šç‚º {paragraphs} æ®µï¼Œæ¯æ®µç´„ 300â€“400 å­—ã€‚"
        )

    constraints_lines.extend([
        "å…¨æ–‡è‡³å°‘åŒ…å« 5 å‰‡ä»¥ä¸Šçš„å—è¨ªè€…ç›´æ¥å¼•è¨€ï¼ˆä½¿ç”¨ã€Œã€æ¨™ç¤ºï¼‰ã€‚",
        "æ¯ä¸€å€‹æ®µè½éƒ½å¿…é ˆæœ‰æ¸…æ¥šçš„å°æ¨™é¡Œï¼Œä½¿ç”¨ã€### å°æ¨™é¡Œã€æ ¼å¼æ¨™ç¤ºã€‚",
        "é–‹å ´æ®µè½ 150â€“200 å­—ï¼Œéœ€è‡ªç„¶éŠœæ¥ä¸»é¡Œï¼Œå…è¨± Â±20 å­—ã€‚"
    ])
    constraints_text = "\n".join(constraints_lines)

    # === é–‹å ´è¨­å®šå€å¡Šï¼ˆæ–°ç‰ˆï¼‰===
    opening_block = _build_opening_block(opening_style, opening_context)

    # === ä½¿ç”¨è€…è¼¸å…¥çµ„è£ ===
    user_prompt = f"""è«‹ä¾ç…§ä»¥ä¸‹æ–‡ç« æ¨¡æ¿ç”Ÿæˆä¸€ç¯‡å®Œæ•´å°ˆè¨ªæ–‡ç« ã€‚

=== æ–‡ç« æ¨¡æ¿ ===
{template_prompt}

=== ç”¢å‡ºé™åˆ¶ ===
{constraints_text}

=== é–‹å ´è¨­å®šï¼ˆå¿…é ˆéµå¾ªï¼‰ ===
{opening_block}

=== ä½¿ç”¨è€…è³‡æ–™ ===
ä¸»é¡Œï¼š{subject}
ä¼æ¥­åç¨±ï¼š{company}
äººç‰©å§“åï¼š{people}
å—è¨ªè€…æ¸…å–®ï¼š{participants}

é€å­—ç¨¿ï¼ˆå·²æ¸…ç†ï¼‰ï¼š
{transcript}

é‡é»æ‘˜è¦ï¼š
{summary_points}
"""

    # ==========================================================
    # ğŸ”¹ å‘¼å«æ¨¡å‹
    # ==========================================================
    def call_model(prompt: str, sys: str, temperature=0.7, max_tokens=3500) -> str:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": sys},
                {"role": "user", "content": prompt},
            ],
            temperature=temperature,
            max_tokens=max_tokens
        )
        return resp.choices[0].message.content.strip()

    # === ç¬¬ä¸€æ¬¡ç”Ÿæˆ ===
    article = call_model(user_prompt, system_prompt)
    checks = basic_check(article)

    # ==========================================================
    # ğŸ”¹ è‡ªå‹•ä¿®ç¨¿å¾ªç’°
    # ==========================================================
    max_retries, retry_count = 2, 0
    while (not checks["within_range"] or not checks["has_enough_quotes"]) and retry_count < max_retries:
        fix_prompt = f"""ä»¥ä¸‹æ˜¯åˆç¨¿æ–‡ç« ï¼Œè«‹ä¾éœ€æ±‚ä¿®æ­£ï¼ˆä¿æŒèªæ°£èˆ‡å…§å®¹ï¼‰ï¼š

=== ä¿®æ­£è¦æ±‚ ===
{constraints_text}

=== é–‹å ´è¨­å®š ===
{opening_block}

=== åˆç¨¿ ===
{article}

è«‹æ ¹æ“šã€Œé–‹å ´è¨­å®šã€åŠã€Œé€šç”¨è¦å‰‡ã€ä¿®æ­£ç¯‡å¹…èˆ‡çµæ§‹ï¼Œ
é¿å…é‡è¤‡æˆ–æ‹–æ²“ï¼Œç¢ºä¿èªæ°£è‡ªç„¶æµæš¢ã€‚
"""
        article = call_model(
            fix_prompt,
            "ä½ æ˜¯å°ˆæ¥­ç·¨è¼¯ï¼Œè² è²¬èª¿æ•´æ–‡ç« çµæ§‹èˆ‡ç¯‡å¹…ã€‚",
            temperature=0.5
        )
        checks = basic_check(article)
        retry_count += 1

    return article, checks, retry_count


# ==========================================================
# ğŸ”¹ æ¸¬è©¦åŸ·è¡Œ
# ==========================================================
if __name__ == "__main__":
    try:
        context_example = {
            "interviewee": "å¼µç‘‹ï¼Œå»ºç¯‰å¸«",
            "topic": "èˆŠåŸå†ç”Ÿè¨ˆç•«",
            "transcript": "ã€Œé‚£è£¡ä»¥å‰æ˜¯æˆ‘çˆ¸çš„å°åˆ·å» ã€‚ã€",
            "setting": "å°ä¸­èˆŠå¸‚å€è€å·¥å» ",
            "datetime": "2025å¹´5æœˆåˆå¾Œ",
            "background": "ç¬¬äºŒä»£å‰µæ¥­è€…",
            "keyData": "åŸå¸‚æ›´æ–°ç¬¬ä¸‰æœŸï¼ŒæŠ•å…¥ç¶“è²»2.3å„„å…ƒ"
        }

        article, checks, retries = generate_article(
            subject="èˆŠåŸå†ç”Ÿèˆ‡é’å¹´å‰µæ¥­",
            company="ç¯‰åŸè¨­è¨ˆäº‹å‹™æ‰€",
            people="å¼µç‘‹",
            participants="å¼µç‘‹ã€è¨­è¨ˆåœ˜éšŠ",
            transcript="é€™æ˜¯è¨ªè«‡é€å­—ç¨¿å…§å®¹...",
            summary_points="1. èˆŠåŸç©ºé–“å†åˆ©ç”¨\n2. é’å¹´è¿”é„‰å‰µæ¥­\n3. ç¶ å»ºç¯‰ç†å¿µæ¨å»£",
            opening_style="å ´æ™¯å¼",
            opening_context=context_example,
            word_count_range=(1500, 2000),
            paragraphs=3
        )

        print(article[:500])
        print("\n=== æª¢æŸ¥çµæœ ===")
        print(checks)
        print(f"ä¿®ç¨¿æ¬¡æ•¸: {retries}")

    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}")

# === blocks utilities: parse / rebuild / regenerate ===
import re
import os
from typing import List, Dict, Optional
from openai import OpenAI

HEADING_RE = re.compile(r"(?m)^###\s+(.+)$")

def parse_article_to_blocks(md: str) -> List[Dict[str, str]]:
    """
    ä¾ '### å°æ¨™é¡Œ' è§£ææ–‡ç« ç‚ºå€å¡Šï¼š
    æ¯å€‹å€å¡Šï¼š{"role": "opening|body|closing", "title": str, "content": str}
    è¦å‰‡ï¼šç¬¬ä¸€å¡Šé è¨­ openingï¼›æœ€å¾Œä¸€å¡Šè‹¥æ¨™é¡Œå«ã€Œæ”¶å°¾/çµèª/çµè«–/å±•æœ›ã€å‰‡ closingï¼Œå¦å‰‡æœ€å¾Œä¸€å¡Šäº¦è¦–ç‚º closingã€‚
    å…¶é¤˜ç‚º bodyã€‚
    """
    md = md.replace("\r\n", "\n").strip()
    matches = list(HEADING_RE.finditer(md))
    blocks = []

    if not matches:
        # æ²’æœ‰å°æ¨™,æ•´ç¯‡è¦–ç‚ºå–®ä¸€ opening
        return [{"role": "opening", "title": "é–‹å ´", "content": md}]

    for i, m in enumerate(matches):
        title = m.group(1).strip()
        start = m.end()
        end = matches[i+1].start() if i + 1 < len(matches) else len(md)
        content = md[start:end].strip()
        blocks.append({"role": "body", "title": title, "content": content})

    # èª¿æ•´é¦–å°¾è§’è‰²
    if blocks:
        blocks[0]["role"] = "opening"
        # åˆ¤æ–·æœ€å¾Œä¸€å¡Šæ˜¯å¦ç‚ºæ”¶å°¾
        closing_keywords = ("æ”¶å°¾", "çµèª", "çµè«–", "å±•æœ›")
        if any(k in blocks[-1]["title"] for k in closing_keywords):
            blocks[-1]["role"] = "closing"
        else:
            # è‹¥æ²’æœ‰æ˜ç¤ºé—œéµè©,ä¹Ÿå°‡æœ€å¾Œä¸€å¡Šç•¶ä½œ closingï¼ˆå¯¦å‹™è¼ƒç©©å®šï¼‰
            blocks[-1]["role"] = "closing"

    return blocks


def build_article_from_blocks(blocks: List[Dict[str, str]]) -> str:
    """
    æŠŠå€å¡Šçµ„å› Markdownï¼šæ¯å¡Šä»¥ "### {title}\n\n{content}" å½¢å¼ä¸²æ¥
    """
    parts = []
    for b in blocks:
        title = b.get("title", "").strip() or "å°æ¨™é¡Œ"
        content = (b.get("content", "") or "").strip()
        parts.append(f"### {title}\n\n{content}".strip())
    return "\n\n".join(parts).strip()


def _clip(text: str, n: int = 800) -> str:
    """
    åœ¨å¥å­é‚Šç•Œè£å‰ªæ–‡å­—,é¿å…èªæ„æ–·è£‚
    å„ªå…ˆåœ¨å¥è™Ÿã€å•è™Ÿã€é©šå˜†è™Ÿè™•åˆ‡æ–·
    """
    text = text.strip()
    if len(text) <= n:
        return text
    
    # å˜—è©¦åœ¨å¥å­é‚Šç•Œ(ã€‚ï¼?)åˆ‡æ–·
    cutoff = text[:n]
    for sep in ("ã€‚", "!", "?", "!", "?"):
        last_idx = cutoff.rfind(sep)
        if last_idx > n * 0.6:  # è‡³å°‘ä¿ç•™ 60% å…§å®¹
            return text[:last_idx + 1] + "â€¦"
    
    # æ‰¾ä¸åˆ°å¥å­é‚Šç•Œ,å˜—è©¦åœ¨é€—è™Ÿæˆ–ç©ºæ ¼åˆ‡
    for sep in (",", "ã€", " "):
        last_idx = cutoff.rfind(sep)
        if last_idx > n * 0.7:
            return text[:last_idx] + "â€¦"
    
    # æœ€å¾Œæ–¹æ¡ˆ:ç›´æ¥åˆ‡æ–·
    return text[:n] + "â€¦"


def regenerate_block(
    index: int,
    blocks: List[Dict[str, str]],
    meta: Dict,
    api_key: Optional[str] = None,
    model: str = "gpt-4o-mini",
) -> Dict[str, str]:
    """
    åªé‡ç”ŸæŒ‡å®š index çš„å€å¡Š,ä¸¦ä¿æŒèˆ‡ä¸Šä¸‹æ–‡ä¸€è‡´ã€‚
    åƒè€ƒ metaï¼šsubject/company/people/participants/summary_points/opening_style/opening_context/paragraphs/word_count_range
    å›å‚³æ–°çš„å€å¡Š dictï¼ˆå« title/contentï¼‰
    è‹¥ç™¼ç”ŸéŒ¯èª¤,å›å‚³åŸå€å¡Šä»¥é¿å…è³‡æ–™éºå¤±
    """
    # é©—è­‰ç´¢å¼•
    if not (0 <= index < len(blocks)):
        raise ValueError(f"å€å¡Šç´¢å¼• {index} è¶…å‡ºç¯„åœ [0, {len(blocks)-1}]")
    
    target = blocks[index]
    
    try:
        client = OpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))

        # ä¸Šä¸‹æ–‡æ‘˜è¦ï¼šå‰å¾Œå„ 1 å¡Š,é¿å… prompt éé•·
        prev_ctx = build_article_from_blocks(blocks[max(0, index-1):index]) if index > 0 else ""
        next_ctx = build_article_from_blocks(blocks[index+1:min(len(blocks), index+2)]) if index < len(blocks)-1 else ""

        role = target.get("role", "body")
        title = target.get("title", "å°æ¨™é¡Œ").strip()
        content = target.get("content", "").strip()

        # åŸºç¤é™åˆ¶
        wc = meta.get("word_count_range", (1500, 2000))
        paragraphs_cnt = meta.get("paragraphs", 3)

        # æ®µè½å­—æ•¸å»ºè­°ï¼ˆé–‹å ´/æ”¶å°¾è¼ƒçŸ­ï¼‰
        if role == "opening":
            per_block_min, per_block_max = 100, 180
        elif role == "closing":
            per_block_min, per_block_max = 100, 160
        else:
            per_block_min, per_block_max = 300, 420

        # é–‹å ´é¢¨æ ¼è¨­å®šï¼ˆè‹¥é‡ç”Ÿ opening å°±ç‰¹åˆ¥åŠ å…¥ï¼‰
        opening_style = meta.get("opening_style", "å ´æ™¯å¼")
        opening_context = meta.get("opening_context", "")

        # ç³»çµ±èˆ‡ä½¿ç”¨è€…è¨Šæ¯
        sys = "ä½ æ˜¯è³‡æ·±æ¡è¨ªç·¨è¼¯,æ“…é•·åœ¨ä¸æ”¹è®Šæ–‡ç« æ—¢æœ‰å…§å®¹ä¸»æ—¨ä¸‹,ä¿®å¯«å–®ä¸€æ®µè½ä¸¦ç¶­æŒå…¨ç¯‡èªæ°£ä¸€è‡´ã€‚"

        # ç›®æ¨™æ®µè½ä»»å‹™èªªæ˜
        task_lines = [
            f"æ®µè½è§’è‰²ï¼š{role}ï¼ˆtitle: {title}ï¼‰",
            f"è«‹é‡å¯«ã€å–®ä¸€æ®µè½ã€,å­—æ•¸å»ºè­° {per_block_min}â€“{per_block_max} å­—,ä¿æŒæµæš¢ã€ä¸è´…è¿°ã€‚",
            "ä¿ç•™äº‹å¯¦èˆ‡ä¸»æ—¨,ä¸è¦ç¯¡æ”¹æ—¢æœ‰è³‡è¨Šæˆ–æé€ å¼•ç”¨ã€‚",
            "ç¶­æŒå…¨ç¯‡èªæ°£ä¸€è‡´ï¼›ä½¿ç”¨ã€### å°æ¨™é¡Œã€+ å…§å®¹ çš„æ ¼å¼è¼¸å‡ºã€‚",
            "è‹¥ç‚ºä¸»é«”æ®µè½,è‡³å°‘åŒ…å«ä¸€å‰‡å—è¨ªè€…å¼•è¨€ï¼ˆä½¿ç”¨ã€Œã€ï¼‰ã€‚",
        ]
        if role == "opening":
            task_lines.extend([
                f"æ­¤æ®µç‚ºé–‹å ´,éœ€éµå¾ªé¢¨æ ¼ï¼š{opening_style}ï¼›åƒè€ƒæ¡è¨ªæƒ…å¢ƒï¼š{opening_context}",
                "é–‹å ´éœ€è‡ªç„¶éŠœæ¥ä¸»é¡Œ,é¿å…å¥—è©±èˆ‡ç©ºæ³›å½¢å®¹è©ã€‚"
            ])
        if role == "closing":
            task_lines.append("æ­¤æ®µç‚ºæ”¶å°¾,éœ€ç¸½çµæ–¹æ³•è«–/åƒ¹å€¼è§€,ä¸¦è‡ªç„¶æ”¶æŸã€‚")

        task_text = "\n".join(f"- {t}" for t in task_lines)

        # çµ„åˆ prompt
        user_prompt = f"""è«‹åªé‡å¯«ã€å–®ä¸€æ®µè½ã€,ä¸¦ä¿æŒèˆ‡ä¸Šä¸‹æ–‡ä¸€è‡´ã€‚

=== åŸºæœ¬è³‡æ–™ ===
ä¸»é¡Œï¼š{meta.get('subject','')}
ä¼æ¥­åç¨±ï¼š{meta.get('company','')}
äººç‰©å§“åï¼š{meta.get('people','')}
å—è¨ªè€…æ¸…å–®ï¼š{meta.get('participants','')}

é‡é»æ‘˜è¦ï¼š
{meta.get('summary_points','')}

=== ä¸Šæ–‡åƒè€ƒï¼ˆä¸å¯çŸ›ç›¾,ä¸è¦æ”¹å‹•ï¼‰ ===
{_clip(prev_ctx, 400)}

=== å¾…é‡å¯«æ®µè½ï¼ˆåŸå§‹ï¼‰ ===
### {title}

{_clip(content, 600)}

=== ä¸‹æ–‡åƒè€ƒï¼ˆä¸å¯çŸ›ç›¾,ä¸è¦æ”¹å‹•ï¼‰ ===
{_clip(next_ctx, 400)}

=== å¯«ä½œä»»å‹™ ===
{task_text}

=== è¼¸å‡ºæ ¼å¼ ===
è«‹åªè¼¸å‡ºè©²æ®µè½,åŒ…å«ä¸€è¡Œå°æ¨™é¡Œï¼ˆ### ï¼‰èˆ‡å…¶å¾Œçš„å…§å®¹,ä¸è¦é¡å¤–å¤šæ®µèªªæ˜ã€‚
"""

        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": sys},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.6,
            max_tokens=900,
        )
        out = resp.choices[0].message.content.strip()

        # è§£æè¼¸å‡ºï¼šå–ç¬¬ä¸€å€‹ "### " åšç‚ºæ–°æ¨™é¡Œï¼›å…¶å¾Œç‚ºå…§å®¹
        m = re.search(r"(?m)^###\s+(.+)$", out)
        if m:
            new_title = m.group(1).strip()
            new_content = out[m.end():].strip()
        else:
            # è‹¥æ¨¡å‹æœªå«æ¨™é¡Œ,ä¿ç•™åŸæ¨™é¡Œ
            new_title = title
            new_content = out

        return {"role": role, "title": new_title, "content": new_content}
    
    except Exception as e:
        print(f"âš ï¸ é‡ç”Ÿå€å¡Š {index} å¤±æ•—: {e}")
        print(f"   åŸå› : {type(e).__name__}")
        # å›å‚³åŸå€å¡Š,é¿å…è³‡æ–™éºå¤±
        return target.copy()