# ==========================================================
#  generator.pyï¼ˆæœ€çµ‚ç©©å®šç‰ˆï¼‰
#  - å®Œæ•´æ”¯æ´æ–°ç‰ˆ OpenAI SDK (v2.x)
#  - è‡ªå‹•æ¸…é™¤èˆ‡æ””æˆª proxies å•é¡Œ
# ==========================================================

# ---- Hard guard for unexpected 'proxies' in any OpenAI() init ----
import os

# 1ï¸âƒ£ æ“´å¤§æ¸…é™¤æ‰€æœ‰å¯èƒ½çš„ä»£ç†ç’°å¢ƒè®Šæ•¸
for _k in [
    "HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY",
    "http_proxy", "https_proxy", "all_proxy",
    "OPENAI_HTTP_PROXY", "OPENAI_PROXY",
    "openai_http_proxy", "openai_proxy"
]:
    if _k in os.environ:
        print(f"âš ï¸ æ¸…é™¤ä»£ç†ç’°å¢ƒè®Šæ•¸ï¼š{_k}")
        os.environ.pop(_k, None)

# 2ï¸âƒ£ é€šçŸ¥ SDK ä¸èµ°ä»»ä½•ä»£ç†
os.environ["NO_PROXY"] = "*"
os.environ["no_proxy"] = "*"

# 3ï¸âƒ£ æ””æˆª OpenAI() åˆå§‹åŒ–ä¸­çš„ proxies
try:
    from openai import OpenAI as _SDKOpenAI
    _old_init = _SDKOpenAI.__init__

    def _patched_init(self, *args, **kwargs):
        if "proxies" in kwargs:
            print("âš ï¸ åµæ¸¬åˆ° proxies åƒæ•¸ï¼Œå·²è‡ªå‹•ç§»é™¤ä»¥é¿å… SDK éŒ¯èª¤ã€‚")
            kwargs.pop("proxies", None)
        # å˜—è©¦æ¸…é™¤ http_client å…§çš„ä»£ç†è¨­å®š
        if "http_client" in kwargs:
            try:
                http_client = kwargs["http_client"]
                if hasattr(http_client, "proxies"):
                    setattr(http_client, "proxies", None)
            except Exception:
                pass
        return _old_init(self, *args, **kwargs)

    _SDKOpenAI.__init__ = _patched_init
    print("âœ… OpenAI() åˆå§‹åŒ– proxies é˜²è­·å·²å•Ÿç”¨")
except Exception as _e:
    print(f"â„¹ï¸ OpenAI() è£œä¸ç•¥éï¼š{_e}")

# ==========================================================
# ä¸»è¦ç”Ÿæˆé‚è¼¯
# ==========================================================
import openai
from typing import Dict, Tuple, List, TypedDict
from engine.template_loader import load_template

# === å¸¸æ•¸å®šç¾© ===
TRANSCRIPT_LENGTH_THRESHOLD = 8000
MAX_SEGMENT_LENGTH = 5000
DEFAULT_MODEL = "gpt-5-mini"
SUMMARY_MODEL = "gpt-4-turbo"
MAX_TOKENS_NORMAL = 4000
MAX_TOKENS_SAFE_MODE = 8000
TEMPERATURE = 0.7
TOP_P = 0.9
MAX_API_ATTEMPTS = 1


class ParticipantInfo(TypedDict):
    name: str
    title: str
    weight: str


def generate_article(
    subject: str,
    company: str,
    participants: str,
    transcript: str,
    summary_points: str,
    opening_style: str,
    opening_context: str,
    paragraphs: int,
    api_key: str,
    model: str = DEFAULT_MODEL,
    max_tokens: int = MAX_TOKENS_NORMAL
) -> Tuple[str, Dict, int]:
    """ç”Ÿæˆå°ˆè¨ªæ–‡ç« ï¼ˆæ”¯æ´æ–°ç‰ˆ SDK + å¤šæ¨¡å‹é¸æ“‡ï¼‰"""
    openai.api_key = api_key

    # === æ¨¡å‹åˆ¥å ===
    model_alias = {
        "gpt-5-mini": "gpt-5-mini",
        "gpt-4-turbo": "gpt-4-turbo",
        "gpt-5": "gpt-5",
        "gpt-4o-mini": "gpt-4o-mini",
        "gpt-4o": "gpt-4o",
    }
    selected_model = model_alias.get(model, DEFAULT_MODEL)

    # === è§£æå—è¨ªè€… ===
    participants_info = _parse_participants(participants)
    participants_desc = _format_participants(participants_info)

    # === é•·é€å­—ç¨¿æ¨¡å¼ ===
    transcript_length = _count_chars(transcript)
    safe_mode = transcript_length > TRANSCRIPT_LENGTH_THRESHOLD
    compressed_transcript = transcript

    if safe_mode:
        print(f"âš ï¸ å•Ÿç”¨é•·é€å­—ç¨¿å®‰å…¨æ¨¡å¼ï¼ˆç´„ {transcript_length} å­—ï¼‰")
        compressed_transcript = summarize_long_transcript(transcript, SUMMARY_MODEL, api_key)

    # === è¼‰å…¥æ¨¡æ¿ ===
    try:
        template_text = load_template("article_template.txt")
    except Exception as e:
        raise Exception(f"æ¨¡æ¿è¼‰å…¥å¤±æ•—ï¼š{str(e)}")

    # === Prompt ===
    system_prompt = (
        "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ˆè¨ªå ±å°æ’°ç¨¿äººï¼Œæ“…é•·å°‡é€å­—ç¨¿è½‰åŒ–ç‚ºå…·æ•˜äº‹æ„Ÿèˆ‡é‚è¼¯çµæ§‹çš„å®Œæ•´æ–‡ç« ï¼Œ"
        "èƒ½ç²¾æº–æ§åˆ¶ç¯‡å¹…èˆ‡å¼•ç”¨æ¯”ä¾‹ï¼Œç¬¦åˆä¼æ¥­ï¼æ”¿åºœï¼æ•™è‚²ç­‰æ­£å¼å‡ºç‰ˆéœ€æ±‚ã€‚"
    )

    user_prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šæ’°å¯«å®Œæ•´å°ˆè¨ªæ–‡ç« ï¼Œä¸¦çµåˆæ–‡ç« æ¨¡æ¿ä½œç‚ºåƒè€ƒï¼š

ã€æ–‡ç« è³‡è¨Šã€‘
ä¸»é¡Œï¼š{subject}
ä¼æ¥­ï¼š{company}
æ®µè½æ•¸ï¼š{paragraphs}
é–‹å ´é¢¨æ ¼ï¼š{opening_style}
æ¡è¨ªæƒ…å¢ƒï¼š{opening_context or 'ï¼ˆç„¡ç‰¹å®šæè¿°ï¼‰'}

ã€å—è¨ªè€…è³‡è¨Šã€‘
{participants_desc}

ã€é€å­—ç¨¿æ‘˜è¦å…§å®¹ã€‘
{compressed_transcript}

ã€é‡é»æ‘˜è¦ã€‘
{summary_points or 'ï¼ˆç„¡ç‰¹å®šæ‘˜è¦ï¼‰'}

ã€æ–‡ç« æ¨¡æ¿ã€‘
{template_text}

ã€æ’°å¯«è¦æ±‚ã€‘
1. çµæ§‹ï¼šé–‹å ´ + {paragraphs} æ®µä¸»é«” + çµèª
2. ä¸»è»¸äººç‰©å¼•ç”¨ç¯‡å¹…ç´„ 60â€“70%
3. æ–‡å­—èªæ°£ï¼šå°ˆæ¥­ã€çœŸå¯¦ã€æœ‰ç•«é¢æ„Ÿ
4. æ¯æ®µ 300â€“500 å­—ï¼Œå…¨ç¯‡ç´„ 1600â€“2000 å­—
5. è‹¥æª¢æ¸¬åˆ°ä¸­åœ‹æ…£ç”¨èªï¼Œè«‹è‡ªå‹•ä¿®æ­£ç‚ºå°ç£å¸¸ç”¨èªªæ³•
6. è«‹è¼¸å‡ºå®Œæ•´æ–‡ç« ï¼ˆå«ä¸»æ¨™é¡Œ # èˆ‡å°æ¨™é¡Œ ##ï¼‰ï¼Œæ®µè½ä¹‹é–“ä»¥ç©ºè¡Œåˆ†éš”
"""

    # === å‘¼å« Chat Completions API ===
    for attempt in range(MAX_API_ATTEMPTS):
        try:
            print(f"ğŸ§  ä½¿ç”¨æ¨¡å‹ï¼š{selected_model}")
            from openai import OpenAI  # é¡¯å¼å»ºç«‹ client ç¢ºä¿ç¶“éè£œä¸
            client = OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model=selected_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=TEMPERATURE,
                top_p=TOP_P,
                max_completion_tokens=min(max_tokens, 4000),
            )

            article = response.choices[0].message.content.strip()
            checks = quality_check(article, paragraphs, participants_info)
            return article, checks, attempt

        except Exception as e:
            if attempt == MAX_API_ATTEMPTS - 1:
                raise Exception(f"API å‘¼å«å¤±æ•—ï¼ˆå·²é‡è©¦ {MAX_API_ATTEMPTS} æ¬¡ï¼‰ï¼š{e}")
            print(f"âš ï¸ API å‘¼å«å¤±æ•—ï¼Œæ­£åœ¨é‡è©¦ï¼ˆç¬¬ {attempt + 1} æ¬¡ï¼‰ï¼š{e}")

    raise Exception("æœªé æœŸéŒ¯èª¤ï¼šç”Ÿæˆå¤±æ•—")


def summarize_long_transcript(transcript: str, model: str, api_key: str) -> str:
    """é•·é€å­—ç¨¿æ‘˜è¦æ¨¡å¼"""
    from openai import OpenAI
    client = OpenAI(api_key=api_key)
    segments = _split_transcript(transcript, MAX_SEGMENT_LENGTH)
    summaries = []
    for idx, seg in enumerate(segments, 1):
        print(f"ğŸ§© æ­£åœ¨æ‘˜è¦ç¬¬ {idx} æ®µ / å…± {len(segments)} æ®µ")
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ‘˜è¦å°ˆå®¶ï¼Œè«‹ä¿ç•™äººç‰©è§€é»ã€æ•¸æ“šã€äº‹ä»¶é‚è¼¯ã€‚"},
                    {"role": "user", "content": f"è«‹æ‘˜è¦ä»¥ä¸‹é€å­—ç¨¿å…§å®¹ï¼Œé™ 300â€“400 å­—ï¼š\n{seg}"},
                ],
                temperature=0.5,
                max_completion_tokens=800,
            )
            summaries.append(response.choices[0].message.content.strip())
        except Exception as e:
            summaries.append(f"[æ‘˜è¦å¤±æ•—ï¼š{e}]")
    print("âœ… æ‘˜è¦å®Œæˆï¼Œçµ„åˆç‚ºå£“ç¸®ç‰ˆé€å­—ç¨¿")
    return "\n\n".join(summaries)


def _split_transcript(transcript: str, max_length: int) -> List[str]:
    lines = transcript.split("\n")
    segments, buffer = [], ""
    for line in lines:
        buffer += line + "\n"
        if len(buffer) > max_length:
            segments.append(buffer.strip())
            buffer = ""
    if buffer.strip():
        segments.append(buffer.strip())
    return segments


def _count_chars(text: str) -> int:
    return len(text.replace(" ", "").replace("\n", ""))


def _parse_participants(participants: str) -> List[ParticipantInfo]:
    info = []
    for line in participants.split("\n"):
        line = line.strip()
        if not line:
            continue
        parts = [p.strip() for p in line.split("ï¼")]
        if len(parts) == 3:
            info.append({"name": parts[0], "title": parts[1], "weight": parts[2]})
    return info


def _format_participants(participants_info: List[ParticipantInfo]) -> str:
    if not participants_info:
        return "ï¼ˆæœªæä¾›å—è¨ªè€…è³‡æ–™ï¼‰"
    return "\n".join([
        f"- {p['name']}ï¼ˆ{p['title']}ï¼‰- {'ä¸»è»¸äººç‰©' if p['weight'] == '1' else 'è¼”åŠ©äººç‰©'}"
        for p in participants_info
    ])


def quality_check(article: str, expected_paragraphs: int, participants: List[ParticipantInfo]) -> Dict[str, bool]:
    checks = {}
    checks["åŒ…å«ä¸»æ¨™é¡Œ"] = article.startswith("#")
    checks["åŒ…å«å¼•è¨€"] = "ã€Œ" in article and "ã€" in article
    paragraph_count = article.count("## ")
    checks["æ®µè½æ•¸ç¬¦åˆ"] = abs(paragraph_count - expected_paragraphs) <= 1
    word_count = _count_chars(article)
    checks["å­—æ•¸å……è¶³"] = 1500 <= word_count <= 2500
    main_names = [p["name"] for p in participants if p["weight"] == "1"]
    checks["æåŠä¸»è»¸äººç‰©"] = any(name in article for name in main_names) if main_names else True
    filler_words = ["éå¸¸æˆåŠŸ", "ååˆ†é‡è¦", "æ¥µç‚ºé—œéµ", "ç›¸ç•¶å„ªç§€", "ä»¤äººæ„Ÿå‹•", "å±•ç¾éå‡¡"]
    checks["é¿å…ç©ºæ³›è©å½™"] = not any(word in article for word in filler_words)
    return checks
